# Cloud Native Architecture

## Fundamentals

Cloud native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach.

These techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil.

The basic idea is to break down your application in smaller pieces which makes them more manageable. Instead of providing all functionality in a single application, you have multiple decoupled applications that communicate with each other in a network.

These small, independent applications with a clearly defined scope of functions are often referred to as microservices.

![Structure](https://d36ai2hkxl16us.cloudfront.net/course-uploads/e0df7fbf-a057-42af-8a1f-590912be5460/ch9ud860v954-Monolithicvsmicroservices.png)
Monilithic vs Microservices Architecture

## Characteristics of Clould Native Architecture

### high level of automation

This can be achieved by using modern automation tools and Continuous Integration/Continuous Delivery (CI/CD) pipelines

### self healing

cloud native application frameworks and infrastructure components include health checks which help monitor your application from the inside and automatically restart them if necessary.

### scalable

Scaling your application describes the process of handling more load while still providing a pleasant user experience.

### cost efficient

scaling down your application and the usage-based pricing models of cloud providers can save costs if traffic is low. To optimize your infrastructure usage, orchestration systems like Kubernetes can help with more efficient and denser placing of applications.

### easy to maintain

Using Microservices allows to break down applications in smaller pieces and make them more portable, easier to test and to distribute across multiple teams.

### secure by default

Patterns like zero trust computing(never trust, always verify) mitigates that by requiring authentication from every user and process.

**A good baseline and staring point for your cloud native is [the 12-factor app](https://12factor.net/)** The twelve factor app is a guideline for developing cloud native applications.

## Autoscaling

The autoscaling pattern describes the dynamic adjustment of resources based on the current demand. CPU and memory are the obvious metrics to decide on when to scale applications as load increases or decreases, but other methods based on time or business metrics can also be considered to scale your services up or down.

### horizontal scaling

Describe the process of spawning new compute resources which can be new copies of your application process, virtual machines, or - in a less immediate way - even new racks of servers and other hardware.

### vertical scaling

Describes the change in size of the underlying hardware, which only works within certain hardware limits for bare metal, but also for virtual machines.

![scaling](https://d36ai2hkxl16us.cloudfront.net/course-uploads/e0df7fbf-a057-42af-8a1f-590912be5460/q2cr3c5d6279-Horizontalvsverticalscaling.png)
**horizontal and vertical scaling**

Configuring autoscaling in various environments requires configuring a minimum and maximum limit of instances (virtual machines or containers) and a metric that triggers the scaling.

## Serverless

Resources:

Server, network, virtual machines, operating systems, load balancers, application code. In a nutshell, you can just provide the application code, while the cloud provider chooses the right environment to run your application.

All popular cloud vendors have one or more commercial offerings of proprietary serverless runtimes and a subset of serverless, also known as Function as a Service [FaaS](https://www.youtube.com/watch?v=EOIja7yFScs).

serverless computing has an even stronger focus on the on-demand provisioning and scaling of applications. Autoscaling is an important core concept of serverless and can include scaling and provisioning based on events like incoming requests. This allows for even more precise billing, which can be based on the events mentioned instead of the widespread time-based billing.

the CloudEvents project was founded and provides a specification of how event data should be structured.

## Open Standards

While Docker is often used synonymously with container technologies, the community has committed to the open industry standard of the Open Container Initiative [OCI](https://opencontainers.org/)

1. OCI Spec: image, runtime and distribution specification on how to run, build an distribute containers.
    - Image-spec defines how to build and package container images
    - Runtime-spec speficies the configuration, execution environment and lifecycle of containers.
    - Distribution-spec provides a standard for the distribution of content in general and container images.
2. Container Network Interface (CNI): A specification on how to implement networking for Containers.
3. Container Runtime Interface (CRI): A specification on how to implement container runtimes in container orchestration systems. The Kubernetes Container Runtime Interface (CRI) defines the main gRPC protocol for the communication between the cluster components kubelet and container runtime.
4. Container Storage Interface (CSI):A specification on how to implement storage in container orchestration systems.
5. Service Mesh Interface (SMI): A specification on how to implement Service Meshes in container orchestration systems with a focus on Kubernetes.

## Cloud Native Roles & Site Reliability Engineering

### Cloud Architect

Responsible for adoption of cloud technologies, designing application landscape and infrastructure, with a focus on security, scalability and deployment mechanisms.

### DevOps Engineer

Often described as a simple combination of developer and administrator, but that doesn't do the role justice. DevOps engineers use tools and processes that balance out software development and operations. Starting with approaches to writing, building, and testing software throughout the deployment lifecycle.

### Security Engineer

Perhaps the easiest role to grasp. Nonetheless, the role of security engineers has changed significantly. Cloud technologies have created new attack vectors and these days the role has to be lived much more inclusive and as an integral part of a team.

### DevSecOps Engineer

In an effort to make security an integral part of modern IT environments, the DevSecOps Engineer combines the roles of the previous two. This role is often used to build bridges between more traditional development and security teams.

### Data Engineer

Data engineers face the challenge of collecting, storing, and analyzing the vast amounts of data that are being or can be collected in large systems. This can include provisioning and managing specialized infrastructure, as well as working with that data.

### Full-Stack Developer

An all-rounder who is at home in frontend and backend development, as well as infrastructure essentials.

### Site Reliability Engineer (SRE)

The overarching goal of SRE is to create and maintain software that is reliable and scalable. To achieve this, software engineering approaches are used to solve operational problems and automate operation tasks.

To measure performance and realiability, 3 main metrics:

1. Service Level Objectives (SLO) “Specify a target level for the reliability of your service.” - A goal that is set, for example reaching a service latency of less that 100ms.
2. Service Level Indicators (SLI) “A carefully defined quantitative measure of some aspect of the level of service that is provided” - For example how long a request actually needs to be answered. 
3. Service Level Agreements (SLA) An explicit or implicit contract with your users that includes consequences of meeting (or missing) the SLOs they contain. The consequences are most easily recognized when they are financial – a rebate or a penalty – but they can take other forms.” - Answers the question what happens if SLOs are not met.

Around these metrics, SREs might define an error budget. An error budget defines the amount (or time) of errors your application can have, before actions are taken, like stopping deployments to production.

## Community and Governance

Cloud Native Computing Foundation (CNCF)

The CNCF has a Technical Oversight Committee (TOC) that is responsible for defining and maintaining the technical vision, approving new projects, accepting feedback from the end-user committee, and defining common practices that should be implemented in CNCF projects.

TOC does not control the projects, but encourages them to be self-governing and community owned and practices the principle of “minimal viable governance”.
