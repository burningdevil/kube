# Cloud Native Observablity

## Overview

Conventional monitoring for servers may include collecting basic metrics of the system like CPU and memory resource usage and logging of processes and the operating system. A new challenge for a microservice architecture is monitoring requests that move through a distributed system. That discipline is called tracing and is especially useful when a lot of services are involved in answering a request.  
relying on collecting metrics and logs, but changes the requirements quite a bit. There is a lot more focus on network problems like latency, throughput, retrying of requests or application start time, while the sheer volume of metrics, logs, and traces in distributed systems calls for a different approach to managing these systems.

## Observability

Observability is often used synonymously with monitoring, but monitoring is only one of the subcategories of cloud native observability and does not do justice to its scope.

Automating your systems in such a way can be very challenging and is not the most important usage of observability.

Observability should give answers to questions like:

- Is the system stable or does it change its state when manipulated?
- Is the system sensitive to change, e.g. if some services have high latency?
- Do certain metrics in the system exceed their limits?
- Why does a request to the system fail?
- Are there any bottlenecks in the system?

The higher goal of observability is to allow analysis of the collected data. This helps to get a better understanding of the system and react to error states.

## Telemetry

The term telemetry has Greek roots and means remote or distance (tele) and measuring (metry). Measuring and collecting data points and then transferring it to another system is of course not exclusive to cloud native or even IT systems.

In container systems, each and every application should have tools built in that generate information data, which is then collected and transferred in a centralized system. The data can be divided into three categories.

### Logs

These are messages that are emitted from an application when errors, warnings or debug information should be presented. A simple log entry could be the start and end of a specific task that the application performed.

```bash
# Return snapshot logs from pod nginx with only one container
# -f real time log
kubectl logs nginx 

# Return snapshot of previous terminated ruby container logs from pod web-1
kubectl logs -p -c ruby web-1 

# Begin streaming the logs of the ruby container in pod web-1
kubectl logs -f -c ruby web-1 

# Display only the most recent 20 lines of output in pod nginx
kubectl logs --tail=20 nginx 

# Show all logs from pod nginx written in the last hour
kubectl logs --since=1h nginx
```

To manage the huge amount of data, these logs need to be shipped to a system that stores the logs. To ship the logs, different methods can be used:  

- node-level logging  
The most efficient way to collect logs. An administrator configures a log shipping tool that collects logs and ships them to a central store.
- logging via sidecar container  
The application has a sidecar container that collects the logs and ships them to a central store.
- Application level logging  
The application pushes the logs directly to the central store. While this seems very convenient at first, it requires configuring the logging adapter in every application that runs in a cluster.

There are several tools to choose from to ship and store the logs. The first two methods can be done by tools like **fluentd or filebeat**.

Popular choices to store logs are **OpenSearch or Grafana Loki**.

Using json instead of plaintext. Structured logging.

### Metrics

Metrics are quantitative measurements taken over time. This could be the number of requests or an error rate.

#### Prometheus

Prometheus is an open source monitoring system, originally developed at SoundCloud.

Prometheus can collect metrics that were emitted by applications and servers as time series data - these are very simple sets of data that include a timestamp, label and the measurement itself. The Prometheus data model provides four core metrics:  

- Counter:  
Only increase, like the number of requests
- Gauge:  
Values the increase or decrease, like memory size
- Histogram:  
A sample of observations, like request duration or response size
- Summary:  
Similar to a histogram, but also provides the total count of observations.

To expose these metrics, applications can expose an HTTP endpoint under /metrics instead of implementing it yourself. You can use the existing client libraries:  
Go/Java or Scala/Python/Ruby

Prometheus has built-in support for Kubernetes and can be configured to automatically discover all services in your cluster and collect the metric data in a defined interval to save them in a time series database.

To query data that is stored in the time series database, Prometheus provides a querying language called PromQL (Prometheus Query Language). A user can use PromQL to select and aggregate data in real time and view it in the built-in Prometheus user interface, which offers a simple graphical or tabular view.

```bash
# Return all time series with the metric http_requests_total and the given job and handler labels:
http_requests_total{job="apiserver", handler="/api/comments"}

# Or a sample function that gives a rate over time:

# Return the per-second rate for all time series with the http_requests_total metric name, as measured over the last 5 minutes:
rate(http_requests_total[5m])
```

**Grafana** which can be used to build dashboards from the collected metrics. You can use Grafana for many more data sources and not only

Another tool from the Prometheus ecosystem is the **Alertmanager**. The Prometheus server itself allows you to configure alerts when certain metrics reach or pass a threshold. When the alert is firing, Alertmanager can send a notification out to your favorite persistent chat tool, e-mail or specialized tools that are made for alerting and on-call management.

### Traces

They track the progression of a request while it’s passing through the system. Traces are used in a distributed system that can provide information about when a request was processed by a service and how long it took.

transmit the data like logs to a centralized system.

A trace consists of multiple units of work which represent the different events that occur while the request is passing the system. Each application can contribute a span to the trace, which can include information like start and finish time, name, tags or a log message.

These traces can be stored and analyzed in a tracing system like **Jaeger**.

While tracing was a new technology and method that was geared towards cloud native environments, there were again problems in the area of standardization. In 2019, the OpenTracing and OpenCensus projects merged to form the OpenTelemetry project, which is now also a CNCF project.

## Cost Management

There are several ways to do automatic and manual optimization.

### Identify wasted and unused resources

With a good monitoring of your resource usage, it is very easy to find unused resources or servers that don’t have a lot of idle time. A lot of cloud vendors have cost explorers that can break down costs for individual services. Autoscaling helps to shut down instances that are not needed.

### Right-Sizing

When you start out, it can be a good idea to choose servers and systems with a lot more power than actually needed. Again, good monitoring can give you indications over time of how much resources are actually needed for your application. This is an ongoing process where you should always adapt to the load you really need. Don’t buy powerful machines if you only need half of their capacity.

### Reserved Instances

On-demand pricing models are great if you really need resources on-demand. Otherwise, you’re probably paying a lot for the "on-demand" service. A method to save a lot of money is to reserve resources and even pay for them upfront. This is a great pricing model if you have a good estimate about the resources you need, maybe even for years in advance.

### Spot Instances

If you have a batch job or heavy load for a short amount of time, you can use spot instances to save money. The idea of spot instances is that you get unused resources that have been over-provisioned by the cloud vendor for very low prices. The "problem" is that these resources are not reserved for you, and can be terminated on short notice to be used by someone else paying "full price".